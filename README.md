# ğŸš€ Document Search & Summarization Using Large Language Models (LLM)
*A Production-Ready Hybrid Retrieval & Summarization System*

---

## ğŸ“Œ Overview

This project implements a **production-style document search and summarization system** using a hybrid retrieval pipeline (BM25 + dense embeddings) combined with LLM-based abstractive summarization.

The system is designed to:
- Efficiently search thousands of documents  
- Return the most relevant chunks using hybrid retrieval  
- Generate coherent, query-focused summaries  
- Provide an interactive UI using Streamlit  

This architecture is inspired by real-world Retrieval-Augmented Generation (RAG) systems used in enterprise AI products.

---

## ğŸ§  Key Features

### ğŸ” Hybrid Search Engine
- **BM25** for keyword-level relevance  
- **Sentence-BERT embeddings** for semantic search  
- **Weighted score fusion** ensures optimal retrieval precision & recall  

### ğŸ“„ LLM-Based Summarization
- Uses GPT models for concise, high-quality summaries  
- Adjustable summary lengths (`short`, `medium`, `long`)  
- Strict grounding to retrieved content to avoid hallucinations  

### âš™ï¸ Modular Pipeline
- Data preprocessing  
- Document chunking  
- Embedding generation  
- FAISS vector indexing  
- BM25 lexical indexing  
- Streamlit UI  

---

## ğŸ—ï¸ System Architecture

                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚        User (UI)         â”‚
                   â”‚  Streamlit Application   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ Query
                                 â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚      Application Backend (Python)   â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Hybrid Retrieval Engine (Core Search Logic)            â”‚
        â”‚                                                        â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
        â”‚  â”‚  BM25 Index   â”‚    â”‚  FAISS Vector   â”‚              â”‚
        â”‚  â”‚ (Lexical IR)  â”‚    â”‚    Index        â”‚              â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
        â”‚          â”‚                       â”‚                    â”‚
        â”‚          â””â”€â”€â”€â”€â”€â”€ Score Fusion â”€â”€â”€â”˜                    â”‚
        â”‚                                                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ Top-K Retrieved Chunks
                          â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚     LLM Summarization Layer    â”‚
             â”‚ (OpenAI GPT-4o-mini / GPT-4o)   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚ Summary
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Streamlit UI Output      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ“‚ Folder Structure

project/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ chunks.json
â”‚ â”œâ”€â”€ chunks.pkl
â”‚ â”œâ”€â”€ embeddings.npy
â”‚ â”œâ”€â”€ faiss_index.bin
â”‚ â””â”€â”€ bm25.pkl
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ chunker.py
â”‚ â”œâ”€â”€ indexer.py
â”‚ â”œâ”€â”€ retriever.py
â”‚ â”œâ”€â”€ summarizer.py
â”‚ â”œâ”€â”€ run_preprocess.py
â”‚ â”œâ”€â”€ run_chunking.py
â”‚ â”œâ”€â”€ run_indexing.py
â”‚ â””â”€â”€ test_retriever.py
â”‚
â”œâ”€â”€ streamlit_app.py
â””â”€â”€ README.md

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Clone the repository
git clone <repo-url>
cd project

2ï¸âƒ£ Create virtual environment
python -m venv .venv
.venv\Scripts\activate   # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set OpenAI API key
setx OPENAI_API_KEY "your_api_key_here"

ğŸ“˜ Pipeline Execution
Step 1 â€” Preprocess Documents
python -m src.run_preprocess

Step 2 â€” Chunk Documents
python -m src.run_chunking

Step 3 â€” Build Retrieval Indexes
python -m src.run_indexing

Step 4 â€” Test Retrieval
python -m src.test_retriever

ğŸ–¥ï¸ Streamlit Interface

Run:

streamlit run streamlit_app.py

